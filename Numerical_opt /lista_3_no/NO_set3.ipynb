{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.1** (3 pts)\n",
    "\n",
    "In this problem we consider univariate function $f:\\mathbb R\\to\\mathbb R$.\n",
    "Let us remind the idea of bracketing method\n",
    "> _Bracketing_ is the process of identifying an interval in which a local minimum lies and then successively shrinking the interval.\n",
    "\n",
    "Implement the method `(a,b) = find_initial_bracket(f)` which for given function $f$ gives the bracketing interval $(a,b)$ such that there exist local minimum $c\\in(a,b)$ satisfying $f(a)>f(c)<f(b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_initial_bracket(f, x=0, s=1e-2, k=2.0):\n",
    "    a, ya = x, f(x)\n",
    "    b, yb = a + s, f(a + s)\n",
    "    if yb > ya:\n",
    "        a, b = b, a\n",
    "        ya, yb = yb, ya\n",
    "        s = -s\n",
    "    while True:\n",
    "        c, yc = b + s, f(b + s)\n",
    "        if yc > yb:\n",
    "            if a > c:\n",
    "                a, c = c, a\n",
    "                return (a,c)\n",
    "            else:\n",
    "                return (a,c)\n",
    "        a, ya, b, yb = b, yb, c, yc\n",
    "        s = s*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.109999999999999, -1.27)\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: 3*x**2 + np.exp(.3*x-9) + 20*x - 20\n",
    "(a,b)= find_initial_bracket(f)\n",
    "print((a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(a, b, .01)\n",
    "plt.plot(x, f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.2** (4 pts)\n",
    "\n",
    "In this problem we consider [unimodal function](https://www.wikiwand.com/en/Unimodality#/Unimodal_function)\n",
    "and will play with _golden section search_ method.\n",
    "\n",
    "First you should implement the _Fibonacci search_ algorithm provided that you have the (global) array of Fibonacci numbers. Next you should implement the _golden section search_ which uses only _golden ratio_ $\\varphi = (1+\\sqrt 5)/2$.\n",
    "\n",
    "* Implement the [Fibonacci search algorithm](https://www.wikiwand.com/en/Golden-section_search#/Fibonacci_search)<br/>`(a, b) = fibonacci_search(f, a, b, n; ε=1e-4)`<br/>to be run on univariate function $f$, with bracketing interval $[a, b]$, for $n > 1$ function evaluations. It should return the new interval $(a, b)$. The optional parameter $\\varepsilon$ should control the lowest-level interval length.\n",
    "* Implement [Golden section search](https://www.wikiwand.com/en/Golden-section_search#)<br/>`(a, b) = gs_search(f, a, b, n)`<br/> to be run on a univariate function $f$ , with bracketing interval $[a, b]$ , for $n > 1$ function evaluations. It returns the new interval $(a, b)$. Guaranteeing convergence to within $\\varepsilon$ requires $n = (b-a)/(\\varepsilon \\ln\\varphi)$.\n",
    "\n",
    "Present the results on various kind of functions.\n",
    "\n",
    "References:\n",
    "- [Fibonacci Search in Optimization of Unimodal Functions](https://www.maplesoft.com/applications/view.aspx?SID=4193&view=html)\n",
    "- [Golden section search](https://www.wikiwand.com/en/Golden-section_search#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fibbonaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def Fib(n): \n",
    "    if n<2: \n",
    "        return n\n",
    "    else: \n",
    "        return Fib(n-1)+Fib(n-2) \n",
    "  \n",
    "  \n",
    "\n",
    "f = lambda x: - x**2 + 21.6*x + 3\n",
    "\n",
    "\n",
    "def fib_search(f,a,b,n,eps = 1e-4):\n",
    "    \n",
    "    n = n+3\n",
    "    \n",
    "    x1 = a + (Fib(n-2)*(b-a))/Fib(n)\n",
    "    x2 = a + (Fib(n-1)*(b-a))/Fib(n)\n",
    "    \n",
    "    if b-a < eps:\n",
    "            return[a,b]\n",
    "    \n",
    "    for i in range(1,n-2):\n",
    "        \n",
    "        \n",
    "        yx1 = f(x1)\n",
    "        yx2 = f(x2)\n",
    "        \n",
    "        if yx1 < yx2:\n",
    "            a = x1\n",
    "            x1 = x2\n",
    "            x2 = a + (Fib(n-1-i)*(b-a))/Fib(n-i)\n",
    "        \n",
    "        else:\n",
    "            b = x2\n",
    "            x2 = x1\n",
    "            x1 =a + (Fib(n-2-i)*(b-a))/Fib(n-i)\n",
    "        \n",
    "        print(f\"[{round(a,4)},{round(b,4)}] with len {round(b-a,5)}, iter:{i}\")\n",
    "    \n",
    "    return [a,b], round((a+b)/2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how our function is doing we will try on on $f(x) = -x^2 + 21.6x +3$.\n",
    "\n",
    "Of course we can check it for any other function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.0983,50] with len 30.9017, iter:1\n",
      "[30.9017,50] with len 19.0983, iter:2\n",
      "[38.1966,50] with len 11.8034, iter:3\n",
      "[42.7051,50] with len 7.2949, iter:4\n",
      "[45.4915,50] with len 4.5085, iter:5\n",
      "[47.2136,50] with len 2.7864, iter:6\n",
      "[48.2779,50] with len 1.72209, iter:7\n",
      "[48.9357,50] with len 1.06431, iter:8\n",
      "[49.3422,50] with len 0.65778, iter:9\n",
      "[49.5935,50] with len 0.40653, iter:10\n",
      "[49.7488,50] with len 0.25125, iter:11\n",
      "[49.8447,50] with len 0.15528, iter:12\n",
      "[49.904,50] with len 0.09596, iter:13\n",
      "[49.9407,50] with len 0.05932, iter:14\n",
      "[49.9634,50] with len 0.03664, iter:15\n",
      "[49.9773,50] with len 0.02268, iter:16\n",
      "[49.986,50] with len 0.01396, iter:17\n",
      "[49.9913,50] with len 0.00872, iter:18\n",
      "[49.9948,50] with len 0.00523, iter:19\n",
      "[49.9965,50] with len 0.00349, iter:20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([49.99651045119866, 50], 49.9983)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: - x**2 + 21.6*x + 3\n",
    "f2 = lambda x: - x**2 + 21.6*np.exp(x-15) + 3\n",
    "f3 = lambda x: x**3 - x**4 + 21.6*np.exp(x-15) + 3 - np.log2(x**3-3*x**2)\n",
    "fib_search(f3,0,50,20,.001)  # change f_ for the another outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golden section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import * \n",
    "\n",
    "\n",
    "def gs_search(f,a,b,n):\n",
    "    \n",
    "    gr = (sqrt(5) + 1) / 2\n",
    "    \n",
    "    x1 = b - (b - a) / gr # dzieli tak samo jak fibbonci\n",
    "    x2 = a + (b - a) / gr\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        if f(x1) < f(x2):\n",
    "            a = x1\n",
    "        else:\n",
    "            b = x2\n",
    "            \n",
    "        x1 = b - (b - a) / gr # dzieli tak samo jak fibbonci\n",
    "        x2 = a + (b - a) / gr\n",
    "        \n",
    "        #print(f\"[{round(a,4)},{round(b,4)}] with len {round(b-a,5)}, iter:{i},value {round(min(f(x1),f(x2)),3)}\")\n",
    "        \n",
    "    return[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.9999999999999964, 4.999999999999997]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_intresting =lambda y: (y-2)**2\n",
    "f = lambda x: - x**2 + 21.6*x + 3\n",
    "f2 = lambda x: - x**2 + 21.6*np.exp(x-15) + 3\n",
    "f3 = lambda x: x**3 - x**4 + 21.6*np.exp(x-15) + 3 - np.log2(x**3-3*x**2)\n",
    "\n",
    "gr = (sqrt(5) + 1) / 2\n",
    "eps = 1e-4\n",
    "n =int(round( 4/(eps*np.log(gr))))\n",
    "gs_search(f_intresting,1,5,n) # change f_ for the another outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.3.** (5 pts)\n",
    "\n",
    "Observe that the previous methods require only to evaluate the value of the objective function $f$.\n",
    "From now we assume we know also its derivative.<br/>\n",
    "For example, consider the function\n",
    "$$ f(x) = x^4 + 16x^2 + 18(x-4) e^x\\qquad (x\\in\\mathbb R). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For the next results this is extremley important that if we want to change fuction we should do this in chunk below.Otherwise my_func will always give results of the function that was previously assigned. Our first function is defined as f. To have another function simply change the foruma after '=' mark. *** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512.0, 1366.7667005965964)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import * \n",
    "import numpy as np\n",
    "\n",
    "x = Symbol('x')\n",
    "f = x**4 + 16*x**2 + 18*(x-4)*exp(x)\n",
    "#f = x**2 + 2 - x**4 * log(x**7-3942638)\n",
    "f_prime = diff(f)\n",
    "f = lambdify(x,f)\n",
    "f_prime = lambdify(x, f_prime)\n",
    "def my_func(x,order = 0):\n",
    "    value = f(x)\n",
    "    if order == 0:\n",
    "        return value\n",
    "    elif order ==1:\n",
    "        gradient = f_prime(x)\n",
    "    return value,gradient\n",
    "\n",
    "v,g = my_func(4,1)\n",
    "v,g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bisection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(MIN,MAX,epsilon = 1e-5, max_iter = 65536):\n",
    "    counter = 0 \n",
    "    while counter <= max_iter:\n",
    "        counter += 1 \n",
    "        MID = (MAX + MIN) / 2\n",
    "        \n",
    "        value,gradient = my_func(MID,order = 1)\n",
    "        \n",
    "        #TODO: suboptimality \n",
    "        \n",
    "        suboptimality = MAX - MIN\n",
    "        \n",
    "        if suboptimality <= epsilon:\n",
    "            break\n",
    "        \n",
    "        if gradient > 0:\n",
    "            MAX = MID\n",
    "            \n",
    "        else:\n",
    "            MIN = MID\n",
    "        \n",
    "        print(f\"Interval is {[MIN,MAX]}\")\n",
    "        print(f\"Number of iterations {counter}\")\n",
    "        print(f\"Suboptimal point{MID}\")\n",
    "        print(f\"Suboptimal value {value}\")\n",
    "        \n",
    "    return MID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval is [0.0, 10]\n",
      "Number of iterations 1\n",
      "Suboptimal point0.0\n",
      "Suboptimal value (2+0j)\n",
      "Interval is [5.0, 10]\n",
      "Number of iterations 2\n",
      "Suboptimal point5.0\n",
      "Suboptimal value (-9452.59139342334-1963.4954084936207j)\n",
      "Interval is [7.5, 10]\n",
      "Number of iterations 3\n",
      "Suboptimal point7.5\n",
      "Suboptimal value (-46687.66373180734-9940.195505498954j)\n",
      "Interval is [7.5, 8.75]\n",
      "Number of iterations 4\n",
      "Suboptimal point8.75\n",
      "Suboptimal value (-56547.0242461581-18415.43935856712j)\n",
      "Interval is [8.125, 8.75]\n",
      "Number of iterations 5\n",
      "Suboptimal point8.125\n",
      "Suboptimal value (-62202.94904359106-13691.257900875562j)\n",
      "Interval is [8.4375, 8.75]\n",
      "Number of iterations 6\n",
      "Suboptimal point8.4375\n",
      "Suboptimal value (-69403.08883494341-15922.271169819005j)\n",
      "Interval is [8.59375, 8.75]\n",
      "Number of iterations 7\n",
      "Suboptimal point8.59375\n",
      "Suboptimal value (-71285.04790120028-17134.86687884039j)\n",
      "Interval is [8.59375, 8.671875]\n",
      "Number of iterations 8\n",
      "Suboptimal point8.671875\n",
      "Suboptimal value (-70317.08673731722-17766.501187116075j)\n",
      "Interval is [8.59375, 8.6328125]\n",
      "Number of iterations 9\n",
      "Suboptimal point8.6328125\n",
      "Suboptimal value (-71123.7583933597-17448.540514206357j)\n",
      "Interval is [8.59375, 8.61328125]\n",
      "Number of iterations 10\n",
      "Suboptimal point8.61328125\n",
      "Suboptimal value (-71261.5679510857-17291.170240245632j)\n",
      "Interval is [8.59375, 8.603515625]\n",
      "Number of iterations 11\n",
      "Suboptimal point8.603515625\n",
      "Suboptimal value (-71285.68759321884-17212.885497800457j)\n",
      "Interval is [8.5986328125, 8.603515625]\n",
      "Number of iterations 12\n",
      "Suboptimal point8.5986328125\n",
      "Suboptimal value (-71288.26317213112-17173.84296063814j)\n",
      "Interval is [8.5986328125, 8.60107421875]\n",
      "Number of iterations 13\n",
      "Suboptimal point8.60107421875\n",
      "Suboptimal value (-71287.72270580189-17193.355917581233j)\n",
      "Interval is [8.5986328125, 8.599853515625]\n",
      "Number of iterations 14\n",
      "Suboptimal point8.599853515625\n",
      "Suboptimal value (-71288.176750876-17183.59736178996j)\n",
      "Interval is [8.5986328125, 8.5992431640625]\n",
      "Number of iterations 15\n",
      "Suboptimal point8.5992431640625\n",
      "Suboptimal value (-71288.26554481391-17178.719641957836j)\n",
      "Interval is [8.59893798828125, 8.5992431640625]\n",
      "Number of iterations 16\n",
      "Suboptimal point8.59893798828125\n",
      "Suboptimal value (-71288.27570856125-17176.281171493145j)\n",
      "Interval is [8.59893798828125, 8.599090576171875]\n",
      "Number of iterations 17\n",
      "Suboptimal point8.599090576171875\n",
      "Suboptimal value (-71288.27346990637-17177.50037427313j)\n",
      "Interval is [8.59893798828125, 8.599014282226562]\n",
      "Number of iterations 18\n",
      "Suboptimal point8.599014282226562\n",
      "Suboptimal value (-71288.27529932513-17176.89076477019j)\n",
      "Interval is [8.59893798828125, 8.598976135253906]\n",
      "Number of iterations 19\n",
      "Suboptimal point8.598976135253906\n",
      "Suboptimal value (-71288.27568137697-17176.585966103452j)\n",
      "Interval is [8.59893798828125, 8.598957061767578]\n",
      "Number of iterations 20\n",
      "Suboptimal point8.598957061767578\n",
      "Suboptimal value (-71288.27573931642-17176.433568291246j)\n",
      "Interval is [8.598947525024414, 8.598957061767578]\n",
      "Number of iterations 21\n",
      "Suboptimal point8.598947525024414\n",
      "Suboptimal value (-71288.27573502428-17176.357369765432j)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.598952293395996"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bisection(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.4** (3 pts)\n",
    "\n",
    "Implement the *line_search* algorithm, which general idea is as follow:\n",
    "```julia\n",
    "function line_search(f, x, d)\n",
    "    objective = α -> f(x + α*d)\n",
    "    a, b = bracket_minimum(objective)\n",
    "    α = minimize(objective, a, b)\n",
    "    return x + α*d\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm extremley sorry but I really dont know how it should work and Julia code is not makeing it simpler for me. \n",
    "To do something that is correlated with this problem I implemented method from \n",
    "[Line search](https://en.wikipedia.org/wiki/Line_search)<br/> \n",
    "What is show belowe is `Example use` from this webside. I also changed it a bit. I'm starting from default alpha and moving through the X axis. When I see that sign of my gradinet has changed i know tha I have to go in opposite direction direction but in the same time I'm making alpha smaller. This is working prety well for both cases when $x_0$ is close or very far from the optimal minimal x. Function is ending when value of the   absolute value of gradinet is smaller then epsilon or when number of iterations is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_line_search(f,k,direction, eps = 1e-9,max_iter = 65536):\n",
    "    counter = 0 \n",
    "    alpha = 10\n",
    "    x_k = k\n",
    "    value,grad = my_func(k,order = 1)\n",
    "    \n",
    "    while counter <= max_iter:\n",
    "        \n",
    "        counter += 1\n",
    "        x_k = x_k + alpha*direction\n",
    "        value_k,grad_k = my_func(x_k,order = 1)\n",
    "        \n",
    "        if np.sign(grad) != np.sign(grad_k):\n",
    "            direction = -1*direction\n",
    "            alpha *= 0.1\n",
    "        \n",
    "        grad = grad_k\n",
    "        \n",
    "        if abs(grad) <= eps:\n",
    "            break\n",
    "        \n",
    "#        if alpha <= eps:\n",
    "#            break\n",
    "        \n",
    "        print(f\"Number of iterations {counter}\")\n",
    "        print(f\"my x is  {x_k}\")\n",
    "        print(f\"line_search value {value_k}\")\n",
    "        \n",
    "    return x_k,value_k,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations 1\n",
      "my x is  10\n",
      "line_search value 2390458.3058391255\n",
      "Number of iterations 2\n",
      "my x is  9.0\n",
      "line_search value 737134.5534817845\n",
      "Number of iterations 3\n",
      "my x is  8.0\n",
      "line_search value 219748.97506700445\n",
      "Number of iterations 4\n",
      "my x is  7.0\n",
      "line_search value 62403.19055513676\n",
      "Number of iterations 5\n",
      "my x is  6.0\n",
      "line_search value 16395.436565738462\n",
      "Number of iterations 6\n",
      "my x is  5.0\n",
      "line_search value 3696.436863846379\n",
      "Number of iterations 7\n",
      "my x is  4.0\n",
      "line_search value 512.0\n",
      "Number of iterations 8\n",
      "my x is  3.0\n",
      "line_search value -136.53966461737804\n",
      "Number of iterations 9\n",
      "my x is  2.0\n",
      "line_search value -186.00601956150342\n",
      "Number of iterations 10\n",
      "my x is  2.1\n",
      "line_search value -189.27491100981365\n",
      "Number of iterations 11\n",
      "my x is  2.2\n",
      "line_search value -191.5448373816655\n",
      "Number of iterations 12\n",
      "my x is  2.3000000000000003\n",
      "line_search value -192.58588311733044\n",
      "Number of iterations 13\n",
      "my x is  2.4000000000000004\n",
      "line_search value -192.12987976247817\n",
      "Number of iterations 14\n",
      "my x is  2.3900000000000006\n",
      "line_search value -192.25136805935637\n",
      "Number of iterations 15\n",
      "my x is  2.380000000000001\n",
      "line_search value -192.35514015223544\n",
      "Number of iterations 16\n",
      "my x is  2.370000000000001\n",
      "line_search value -192.44152400581822\n",
      "Number of iterations 17\n",
      "my x is  2.360000000000001\n",
      "line_search value -192.51084271584529\n",
      "Number of iterations 18\n",
      "my x is  2.3500000000000014\n",
      "line_search value -192.56341457440897\n",
      "Number of iterations 19\n",
      "my x is  2.3400000000000016\n",
      "line_search value -192.59955313442748\n",
      "Number of iterations 20\n",
      "my x is  2.330000000000002\n",
      "line_search value -192.61956727328607\n",
      "Number of iterations 21\n",
      "my x is  2.320000000000002\n",
      "line_search value -192.62376125565768\n",
      "Number of iterations 22\n",
      "my x is  2.321000000000002\n",
      "line_search value -192.62404518722758\n",
      "Number of iterations 23\n",
      "my x is  2.322000000000002\n",
      "line_search value -192.62417362039747\n",
      "Number of iterations 24\n",
      "my x is  2.3230000000000017\n",
      "line_search value -192.62414625703917\n",
      "Number of iterations 25\n",
      "my x is  2.3229000000000015\n",
      "line_search value -192.6241560127247\n",
      "Number of iterations 26\n",
      "my x is  2.3228000000000013\n",
      "line_search value -192.62416420775838\n",
      "Number of iterations 27\n",
      "my x is  2.322700000000001\n",
      "line_search value -192.62417084243884\n",
      "Number of iterations 28\n",
      "my x is  2.322600000000001\n",
      "line_search value -192.6241759170648\n",
      "Number of iterations 29\n",
      "my x is  2.3225000000000007\n",
      "line_search value -192.62417943193495\n",
      "Number of iterations 30\n",
      "my x is  2.3224000000000005\n",
      "line_search value -192.62418138734785\n",
      "Number of iterations 31\n",
      "my x is  2.3223000000000003\n",
      "line_search value -192.62418178360213\n",
      "Number of iterations 32\n",
      "my x is  2.3223100000000003\n",
      "line_search value -192.62418181413022\n",
      "Number of iterations 33\n",
      "my x is  2.3223200000000004\n",
      "line_search value -192.62418182906958\n",
      "Number of iterations 34\n",
      "my x is  2.3223300000000004\n",
      "line_search value -192.6241818284197\n",
      "Number of iterations 35\n",
      "my x is  2.3223290000000003\n",
      "line_search value -192.62418182918623\n",
      "Number of iterations 36\n",
      "my x is  2.322328\n",
      "line_search value -192.62418182979684\n",
      "Number of iterations 37\n",
      "my x is  2.322327\n",
      "line_search value -192.62418183025153\n",
      "Number of iterations 38\n",
      "my x is  2.322326\n",
      "line_search value -192.62418183055036\n",
      "Number of iterations 39\n",
      "my x is  2.3223249999999998\n",
      "line_search value -192.62418183069332\n",
      "Number of iterations 40\n",
      "my x is  2.3223239999999996\n",
      "line_search value -192.62418183068036\n",
      "Number of iterations 41\n",
      "my x is  2.3223240999999994\n",
      "line_search value -192.62418183068866\n",
      "Number of iterations 42\n",
      "my x is  2.3223241999999993\n",
      "line_search value -192.62418183069536\n",
      "Number of iterations 43\n",
      "my x is  2.322324299999999\n",
      "line_search value -192.62418183070065\n",
      "Number of iterations 44\n",
      "my x is  2.322324399999999\n",
      "line_search value -192.62418183070417\n",
      "Number of iterations 45\n",
      "my x is  2.322324499999999\n",
      "line_search value -192.62418183070628\n",
      "Number of iterations 46\n",
      "my x is  2.3223245999999986\n",
      "line_search value -192.62418183070685\n",
      "Number of iterations 47\n",
      "my x is  2.3223245899999987\n",
      "line_search value -192.62418183070687\n",
      "Number of iterations 48\n",
      "my x is  2.3223245799999988\n",
      "line_search value -192.62418183070682\n",
      "Number of iterations 49\n",
      "my x is  2.322324580999999\n",
      "line_search value -192.62418183070682\n",
      "Number of iterations 50\n",
      "my x is  2.322324581999999\n",
      "line_search value -192.62418183070682\n",
      "Number of iterations 51\n",
      "my x is  2.322324582999999\n",
      "line_search value -192.62418183070682\n",
      "Number of iterations 52\n",
      "my x is  2.322324583999999\n",
      "line_search value -192.62418183070682\n",
      "Number of iterations 53\n",
      "my x is  2.322324583899999\n",
      "line_search value -192.6241818307069\n",
      "Number of iterations 54\n",
      "my x is  2.322324583799999\n",
      "line_search value -192.62418183070685\n",
      "Number of iterations 55\n",
      "my x is  2.322324583699999\n",
      "line_search value -192.62418183070687\n",
      "Number of iterations 56\n",
      "my x is  2.322324583599999\n",
      "line_search value -192.62418183070685\n",
      "Number of iterations 57\n",
      "my x is  2.322324583499999\n",
      "line_search value -192.6241818307069\n",
      "Number of iterations 58\n",
      "my x is  2.322324583399999\n",
      "line_search value -192.62418183070687\n",
      "Number of iterations 59\n",
      "my x is  2.322324583299999\n",
      "line_search value -192.6241818307069\n",
      "Number of iterations 60\n",
      "my x is  2.322324583199999\n",
      "line_search value -192.6241818307068\n",
      "Number of iterations 61\n",
      "my x is  2.322324583099999\n",
      "line_search value -192.6241818307069\n",
      "Number of iterations 62\n",
      "my x is  2.322324583109999\n",
      "line_search value -192.62418183070685\n",
      "Number of iterations 63\n",
      "my x is  2.322324583119999\n",
      "line_search value -192.6241818307068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.322324583129999, -192.62418183070685, 2.461888470861595e-10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_line_search(f,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.5.** (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracking_line_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking_line_search( f, k, direction, alpha=0.4, beta=0.9, maximum_iterations=65536 ):\n",
    "    counter = 0 \n",
    "    value,grad = my_func(k,order = 1)\n",
    "    x_k = k + alpha*direction\n",
    "    value_k,grad_k = my_func(x_k,order = 1)\n",
    "    \n",
    "    if grad*direction < 0 :\n",
    "        pass\n",
    "    else:\n",
    "        direction = -1*direction\n",
    "    \n",
    "    while value + alpha*beta*grad*direction < value_k:\n",
    "        alpha = 1/2 *alpha\n",
    "        x_k = k + alpha*direction\n",
    "        value_k,grad_k = my_func(x_k,order = 1)\n",
    "        counter += 1 \n",
    "        \n",
    "        print(f\"my alpha {alpha}\")\n",
    "        \n",
    "        if counter > maximum_iterations:\n",
    "            break\n",
    "    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it complicated for the backtracking_line_search f function we will set $f(x) = x^2$ and intial $x_0$ very close to optimal minimum. So alpha really needs to 'melt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my alpha 0.2\n",
      "my alpha 0.1\n",
      "my alpha 0.05\n",
      "my alpha 0.025\n",
      "my alpha 0.0125\n",
      "my alpha 0.00625\n",
      "my alpha 0.003125\n",
      "my alpha 0.0015625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0015625"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Symbol('x')\n",
    "f = x**2\n",
    "f_prime = diff(f)\n",
    "f = lambdify(x,f)\n",
    "f_prime = lambdify(x, f_prime)       \n",
    "\n",
    "backtracking_line_search( f, 0.01, 1, alpha=0.4, beta=0.9, maximum_iterations=65536 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Please if You will have any questions sir, let me know and we will try to figure out what is going on in this madness ;)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made and described by Szymon Czop s292913"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
