{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rafał Nowak\n",
    "# Numerical Optimization\n",
    "## Problem set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.1** (3 pts)\n",
    "\n",
    "In this problem we consider univariate function $f:\\mathbb R\\to\\mathbb R$.\n",
    "Let us remind the idea of bracketing method\n",
    "> _Bracketing_ is the process of identifying an interval in which a local minimum lies and then successively shrinking the interval.\n",
    "\n",
    "Implement the method `(a,b) = find_initial_bracket(f)` which for given function $f$ gives the bracketing interval $(a,b)$ such that there exist local minimum $c\\in(a,b)$ satisfying $f(a)>f(c)<f(b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:22:37.276000+01:00",
     "start_time": "2019-11-05T18:22:35.415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_initial_bracket (generic function with 2 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "function find_initial_bracket(f, x=0; s=1e-2, k=2.0)\n",
    "    a, ya = x, f(x)\n",
    "    b, yb = a + s, f(a + s)\n",
    "    if yb > ya\n",
    "        a, b = b, a\n",
    "        ya, yb = yb, ya\n",
    "        s = -s\n",
    "    end\n",
    "    while true\n",
    "        c, yc = b + s, f(b + s)\n",
    "        if yc > yb\n",
    "            return a < c ? (a, c) : (c, a)\n",
    "        end\n",
    "    a, ya, b, yb = b, yb, c, yc\n",
    "    s *= k\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T19:29:31.994000+01:00",
     "start_time": "2019-11-05T18:29:31.973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a, b) = (-5.109999999999999, -1.27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-5.109999999999999, -1.27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example test\n",
    "f(x) = 3*x^2 + exp(.3*x-9) + 20*x - 20\n",
    "a, b = find_initial_bracket(f)\n",
    "@show a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "using Plotly\n",
    "plot( f, a , b )\n",
    "```\n",
    "<img src=\"f_bracket.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.2** (4 pts)\n",
    "\n",
    "In this problem we consider [unimodal function](https://www.wikiwand.com/en/Unimodality#/Unimodal_function)\n",
    "and will play with _golden section search_ method.\n",
    "\n",
    "First you should implement the _Fibonacci search_ algorithm provided that you have the (global) array of Fibonacci numbers. Next you should implement the _golden section search_ which uses only _golden ratio_ $\\varphi = (1+\\sqrt 5)/2$.\n",
    "\n",
    "* Implement the [Fibonacci search algorithm](https://www.wikiwand.com/en/Golden-section_search#/Fibonacci_search)<br/>`(a, b) = fibonacci_search(f, a, b, n; ε=1e-4)`<br/>to be run on univariate function $f$, with bracketing interval $[a, b]$, for $n > 1$ function evaluations. It should return the new interval $(a, b)$. The optional parameter $\\varepsilon$ should control the lowest-level interval length.\n",
    "* Implement [Golden section search](https://www.wikiwand.com/en/Golden-section_search#)<br/>`(a, b) = gs_search(f, a, b, n)`<br/> to be run on a univariate function $f$ , with bracketing interval $[a, b]$ , for $n > 1$ function evaluations. It returns the new interval $(a, b)$. Guaranteeing convergence to within $\\varepsilon$ requires $n = (b-a)/(\\varepsilon \\ln\\varphi)$.\n",
    "\n",
    "Present the results on various kind of functions.\n",
    "\n",
    "References:\n",
    "- [Fibonacci Search in Optimization of Unimodal Functions](https://www.maplesoft.com/applications/view.aspx?SID=4193&view=html)\n",
    "- [Golden section search](https://www.wikiwand.com/en/Golden-section_search#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frow now we assume that our black box function has additional parameter `order`.\n",
    "The meaning is as follows\n",
    "```julia\n",
    "function my_func(x; order=0)\n",
    "    if order==0\n",
    "        return value\n",
    "    elseif order==1\n",
    "        return value, gradient\n",
    "    elseif order==2\n",
    "        return value, gradient, hessian\n",
    "    else\n",
    "        # raise an  error\n",
    "    end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.3.** (5 pts)\n",
    "\n",
    "Observe that the previous methods require only to evaluate the value of the objective function $f$.\n",
    "From now we assume we know also its derivative.<br/>\n",
    "For example, consider the function\n",
    "$$ f(x) = x^4 + 16x^2 + 18(x-4) e^x\\qquad (x\\in\\mathbb R). $$\n",
    "First implement the function\n",
    "```julia\n",
    "# function gets scalar x as input and returns f(x) and f'(x)\n",
    "function my_func(x, order=0)\n",
    "    value = ____\n",
    "    if order == 0\n",
    "        return value\n",
    "    elseif order == 1\n",
    "        gradient = ____\n",
    "        return (value, gradient)\n",
    "    end\n",
    "end\n",
    "```\n",
    "Do not forget to experiment with other (nice) functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement bisection method to find the minimum of $f$\n",
    "* Initialize the method with $x_{\\text{left}}=-10$ and $x_{\\text{right}}=10$.\n",
    "\n",
    "```julia\n",
    "# bisection gets function f, performs bisection search\n",
    "# on interval [a, b] and returns an eps-suboptimal\n",
    "# solution x; i.e. f(x)-f(x^*) <= eps .\n",
    "function bisection(fun, MIN, MAX; epsilon=1e-5, max_iter=65536)\n",
    "    # counting the number of iterations\n",
    "    counter = 0\n",
    "    while true\n",
    "        counter +=1\n",
    "        MID = ( MAX + MIN ) / 2\n",
    "\n",
    "        # Oracle access to the function value and gradient\n",
    "        value, gradient = fun( MID, order=1 )\n",
    "\n",
    "        # provide an upper bound for the suboptimality of MID in terms of\n",
    "        # the magnitude of the gradient and distance from the optimum\n",
    "        ###############################\n",
    "        # TODO: suboptimality = ???\n",
    "        ###############################\n",
    "\n",
    "        if suboptimality <= eps\n",
    "            break\n",
    "        end\n",
    "\n",
    "        if gradient > 0\n",
    "          ###############################\n",
    "          # TODO: Updating the interval #\n",
    "          ###############################\n",
    "        else\n",
    "          ###############################\n",
    "          # TODO: Updating the interval #\n",
    "          ###############################\n",
    "        end\n",
    "    end\n",
    "    @printf( \"Number of Iterations: %d\", counter )\n",
    "    @printf( \"Suboptimal point: %1.15\"', MID )\n",
    "    @printf( \"Suboptimal value: %1.15\"', value )\n",
    "    return MID    \n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your method with the function $f$ and the following functions (written in Python)\n",
    "```python\n",
    "\n",
    "###############################################################################\n",
    "def boyd_example_func(x, order=0):\n",
    "  a=np.matrix('1  3')\n",
    "  b=np.matrix('1  -3')\n",
    "  c=np.matrix('-1  0')\n",
    "  x=np.asmatrix(x)\n",
    "  \n",
    "  value = exp(a*x-0.1)+exp(b*x-0.1)+exp(c*x-0.1)\n",
    "  if order==0:\n",
    "      return value\n",
    "  elif order==1:\n",
    "      gradient = a.T*exp(a*x-0.1)+b.T*exp(b*x-0.1)+c.T*exp(c*x-0.1)\n",
    "      return (value, gradient)\n",
    "  elif order==2:\n",
    "      gradient = a.T*exp(a*x-0.1)+b.T*exp(b*x-0.1)+c.T*exp(c*x-0.1)\n",
    "      hessian = a.T*a*exp(a*x-0.1)+b.T*b*exp(b*x-0.1)+c.T*c*exp(c*x-0.1)\n",
    "      return (value, gradient, hessian)\n",
    "  else:\n",
    "        raise ValueError(\"The argument \\\"order\\\" should be 0, 1 or 2\")\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def quadratic( H, b, x, order=0 ):\n",
    "    \"\"\" \n",
    "    Quadratic Objective\n",
    "    H:          the Hessian matrix\n",
    "    b:          the vector of linear coefficients\n",
    "    x:          the current iterate\n",
    "    order:      the order of the oracle. For example, order=1 returns the value of the function and its gradient while order=2 will also return the hessian\n",
    "    \"\"\"\n",
    "    H = np.asmatrix(H)\n",
    "    b = np.asmatrix(b)\n",
    "    x = np.asmatrix(x)\n",
    "    \n",
    "    value = 0.5 * x.T * H * x + b.T * x\n",
    "\n",
    "    if order == 0:\n",
    "        return value\n",
    "    elif order == 1:\n",
    "        gradient = H * x + b\n",
    "        return (value, gradient)\n",
    "    elif order == 2:\n",
    "        gradient = H * x + b\n",
    "        hessian = H\n",
    "        return (value, gradient, hessian)\n",
    "    else:\n",
    "        raise ValueError(\"The argument \\\"order\\\" should be 0, 1 or 2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.4** (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the *line_search* algorithm, which general idea is as follow:\n",
    "```julia\n",
    "function line_search(f, x, d)\n",
    "    objective = α -> f(x + α*d)\n",
    "    a, b = bracket_minimum(objective)\n",
    "    α = minimize(objective, a, b)\n",
    "    return x + α*d\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you should implement the function\n",
    "```julia\n",
    "function exact_line_search( f, x, direction, eps=1e-9, maximum_iterations=65536 )\n",
    "    # TODO\n",
    "    \n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T20:03:35.314000+01:00",
     "start_time": "2019-11-05T19:03:35.312Z"
    }
   },
   "source": [
    "where the *bisection* method is used for optimizing in `line_search` and\n",
    "* `f` is the function to optimize; assume one can call it like `value, gradient = f( x, order=1 )`\n",
    "* `x` is the the current iterate\n",
    "* `direction` is the direction along which to perform the linesearch\n",
    "* `eps` is the maximum allowed error in the resulting stepsize $t$\n",
    "* `maximum_iterations` is the maximum allowed number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.5.** (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you should implement backtracking linesearch algorithm\n",
    "```julia\n",
    "function backtracking_line_search( f, x, direction, α=0.4, β=0.9, maximum_iterations=65536 )\n",
    "    # TODO\n",
    "    \n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T20:03:35.314000+01:00",
     "start_time": "2019-11-05T19:03:35.312Z"
    }
   },
   "source": [
    "where the *bisection* method is used for optimizing in `line_search` and\n",
    "* `f` is the function to optimize; assume one can call it like `value, gradient = f( x, order=1 )`\n",
    "* `x` is the the current iterate\n",
    "* `direction` is the direction along which to perform the linesearch\n",
    "* `eps` is the maximum allowed error in the resulting stepsize $t$\n",
    "* `α` is the alpha parameter to backtracking linesearch\n",
    "* `β` is the beta parameter to backtracking linesearch\n",
    "* `maximum_iterations` is the maximum allowed number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3.6** (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the *gradient descent* algorithm using the given linesearch method\n",
    "```julia\n",
    "function gradient_descent( f, x0, eps=1e-5, maximum_iterations=65536, linesearch_algorithm=exact_line_search )\n",
    "    \"\"\"\n",
    "    f:                    the function to optimize It is called as \"value, gradient = func( x, 1 )\n",
    "    x0:                   the starting point\n",
    "    eps:                  the maximum allowed error in the resulting stepsize t\n",
    "    maximum_iterations:   the maximum allowed number of iterations\n",
    "    linesearch_algorithm: the linesearch routine\n",
    "    \"\"\"\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your method with above functions `f`, `boyd` and `quadratic` (with different types of matrix $H$)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
